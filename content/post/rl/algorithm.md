# 算法

Deep Q network 用的比较少了，现在最强的是：Asynchronous Advantage Actor-Critic(A3C)

在智能体执行动作前，是否能对下一步的状态和奖励进行预测，如果可以，就能够对环境进行建模，从而采用有模型学习。

因为 agent 不能够对下一步的状态和奖励进行预测（例如：使用者的评分，周围的观察），因此我们采用无模型算法
