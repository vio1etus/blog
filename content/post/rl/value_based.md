---
title: Value-based Method of RL
comments: true
toc: true
tags:
description: æœ¬æ–‡å­¦ä¹  RL ä¸­çš„ Value-based Method
categories:
    - rl
date: 2020-12-17 16:35:39
tags:
---

## Deep Q-Network

Goal: Win the game (â‰ˆ maximize the total reward.)

Question: If we know $ğ‘„^{\star}(ğ‘ |ğ‘)$, what is the best action?

-   Obviously, the best action is $a_{t} = argmax_{a}Q^{\star}(s_{t},a)$

Challenge: We do not know $ğ‘„^{\star}(ğ‘ |ğ‘)$.

-   Solution: Deep Q Network (DQN)
-   Use neural network $ğ‘„(ğ‘ ,ğ‘;ğ°)$ to approximate $ğ‘„^{\star}(ğ‘ |ğ‘)$, DQN è¾“å…¥å½“å‰çŠ¶æ€ Sï¼Œè¾“å‡ºåŠ¨ä½œç©ºé—´

![20201215201250](https://blog-1259556217.cos.ap-chengdu.myqcloud.com/image/20201215201250.png)

## Apply DQN to Play Game

![20201215201448](https://blog-1259556217.cos.ap-chengdu.myqcloud.com/image/20201215201448.png)

1. è§‚å¯Ÿç¯å¢ƒ, è·å–çŠ¶æ€ $s_{t}$, ä¹Ÿå°±æ˜¯ Observation
2. å‘ DQN è¾“å…¥çŠ¶æ€ $s_{t}$ï¼Œè·å¾—ä½¿å…¶æœ€å¤§åŒ–çš„åŠ¨ä½œ $a_{t}$
3. ç¯å¢ƒæ¥å—åˆ° agent çš„åŠ¨ä½œå½±å“ï¼Œé€šè¿‡çŠ¶æ€è½¬ç§»å‡½æ•° $s_{t+1}~p(\cdot|s_{t},a_{t})$ è·å–ä¸‹ä¸€ä¸ªçŠ¶æ€ $s_{t+1}$
4. ç¯å¢ƒåŒæ—¶ç»™å‡ºæœ¬è½®çš„ reward

## çŠ¶æ€ä»·å€¼å‡½æ•°çš„ä¼°ç®—

### Monte-Carlo Policy Evaluation

![20201215204309](https://blog-1259556217.cos.ap-chengdu.myqcloud.com/image/20201215204309.png)
![20201215203942](https://blog-1259556217.cos.ap-chengdu.myqcloud.com/image/20201215203942.png)

### æ—¶åºå·®åˆ†æ–¹æ³• Temporal-difference (TD) -- å•æ­¥æ›´æ–°

-   Can I update the model before finishing the tripï¼Ÿ
-   Can I get a better ğ° as soon as I arrived at DC?

That's TD learning!

![20201215204718](https://blog-1259556217.cos.ap-chengdu.myqcloud.com/image/20201215204718.png)

TD error

![20201215204809](https://blog-1259556217.cos.ap-chengdu.myqcloud.com/image/20201215204809.png)

#### Apply TD learning to DQN

æƒ³è¦ä½¿ç”¨ TD ç®—æ³•ï¼Œå¿…é¡»ç­‰å¼å·¦è¾¹æœ‰ä¸€é¡¹ï¼Œå³è¾¹æœ‰ä¸¤é¡¹ï¼Œå³è¾¹ä¸¤é¡¹ä¸­æœ‰ä¸€é¡¹ä¸ºçœŸå®è§‚æµ‹åˆ°çš„ã€‚

![20201215205216](https://blog-1259556217.cos.ap-chengdu.myqcloud.com/image/20201215205216.png)

ç®€è¦çš„æ¨å¯¼è¯æ˜ï¼š

![20201215205708](https://blog-1259556217.cos.ap-chengdu.myqcloud.com/image/20201215205708.png)

#### Train DQN using TD learning

![20201215211053](https://blog-1259556217.cos.ap-chengdu.myqcloud.com/image/20201215211053.png)

$Q(s_{t+1},a_{t+1}, w_{t})$ çš„å€¼å®é™…ä¸Šç­‰äºæŠŠ a å½“ä½œå˜é‡æ±‚å¾—çš„æœ€å¤§åŒ– Q å€¼

#### One iteration of TD learning

![20201215211400](https://blog-1259556217.cos.ap-chengdu.myqcloud.com/image/20201215211400.png)
